{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"klue-transformers-tuto_module12.ipynb","provenance":[],"authorship_tag":"ABX9TyP+hWnJxOQtsSzbMIIjC95P"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"b87bf07b6292456e9f593ac0b5967f5d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3fbce56a04874cb5a2acf16ebc08aa85","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_445d32afb0364dc68430410b8b7cf72a","IPY_MODEL_7ef484bdb564483a8e730c9d383f48b3"]}},"3fbce56a04874cb5a2acf16ebc08aa85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"445d32afb0364dc68430410b8b7cf72a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cdd68eab70a04d44a7b75c07d58decf5","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":25,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":25,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e997953b0dce49bc8152f7e43b91951c"}},"7ef484bdb564483a8e730c9d383f48b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64a56163f70649a28c99aff5c1725fd7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 25/25 [00:01&lt;00:00, 13.33ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aa41fa287a644dad8dca2d01830fbcc8"}},"cdd68eab70a04d44a7b75c07d58decf5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e997953b0dce49bc8152f7e43b91951c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64a56163f70649a28c99aff5c1725fd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aa41fa287a644dad8dca2d01830fbcc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed1c2a0949a44034b55b4cb81083b35b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73983738d4b24af3a8dff7f453fce126","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c081f0f3b0324f789e62bde11ec2f008","IPY_MODEL_65a3ee852053471b8e435ed9bd7bf098"]}},"73983738d4b24af3a8dff7f453fce126":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c081f0f3b0324f789e62bde11ec2f008":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0679fe589e9745729937c035ad81021d","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":3,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_630fe4ea9f394f05a2cfabeb89f4e629"}},"65a3ee852053471b8e435ed9bd7bf098":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2553fbac5c2148d082605f8856662986","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3/3 [00:00&lt;00:00, 11.94ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8910c4bab8e24d71b175cfcb58c05b21"}},"0679fe589e9745729937c035ad81021d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"630fe4ea9f394f05a2cfabeb89f4e629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2553fbac5c2148d082605f8856662986":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8910c4bab8e24d71b175cfcb58c05b21":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e4a9a45b3a1498281a1b9b3b906dfda":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3d667f490d3740b0b75d68f5f4510ea1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1cd7b1879c33475583c762e736a40cfc","IPY_MODEL_d0f4d751fa734090a2cb3d63219cf0dd"]}},"3d667f490d3740b0b75d68f5f4510ea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1cd7b1879c33475583c762e736a40cfc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_286a948ae9e349518928376b2405a9e9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":442653775,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":442653775,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6350a75a3ec846d7a67b663cf8981c9a"}},"d0f4d751fa734090a2cb3d63219cf0dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_546e7d4bead042948c5065ba072b897e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 443M/443M [00:54&lt;00:00, 8.10MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_148781bdea454c99806309a20bdebd7e"}},"286a948ae9e349518928376b2405a9e9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6350a75a3ec846d7a67b663cf8981c9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"546e7d4bead042948c5065ba072b897e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"148781bdea454c99806309a20bdebd7e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ubx1fo9pFE8y","executionInfo":{"status":"ok","timestamp":1625212199839,"user_tz":-480,"elapsed":3459,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"3be72b46-db3f-4191-8f55-3881cbcd2911"},"source":["!pip install -U transformers datasets scipy scikit-learn"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: transformers in /usr/local/lib/python3.7/dist-packages (4.8.2)\n","Requirement already up-to-date: datasets in /usr/local/lib/python3.7/dist-packages (1.8.0)\n","Requirement already up-to-date: scipy in /usr/local/lib/python3.7/dist-packages (1.7.0)\n","Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.2)\n","Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n","Requirement already satisfied, skipping upgrade: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied, skipping upgrade: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (2021.6.1)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied, skipping upgrade: pyarrow<4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied, skipping upgrade: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied, skipping upgrade: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.1.0)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TnW-LN_6JR0d"},"source":["## 문장 분류 모델 학습"]},{"cell_type":"code","metadata":{"id":"NuZOUP_bGIYD","executionInfo":{"status":"ok","timestamp":1625212199839,"user_tz":-480,"elapsed":7,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["import random\n","import logging\n","from IPython.display import display, HTML\n","\n","import numpy as np\n","import pandas as pd\n","import datasets\n","from datasets import load_dataset, load_metric, ClassLabel, Sequence\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aH-0fNqLJ6qk"},"source":["학습에 필요한 정보를 변수로 기록합니다.\n","\n","본 노트북에서는 klue-roberta-base 모델을 활용하지만, https://huggingface.co/klue 페이지에서 더 다양한 사전학습 언어 모델을 확인하실 수 있습니다.\n","\n","학습 태스크로는 nli를, 배치 사이즈로는 32를 지정하겠습니다."]},{"cell_type":"code","metadata":{"id":"epcweEhYJUUH","executionInfo":{"status":"ok","timestamp":1625212199840,"user_tz":-480,"elapsed":6,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["model_checkpoint = \"klue/roberta-base\"\n","batch_size = 32\n","task = \"nli\""],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dRXF9iVJ-4z"},"source":["이제 HuggingFace datasets 라이브러리에 등록된 KLUE 데이터셋 중, NLI 데이터를 내려받습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPX1xYUrJ9LG","executionInfo":{"status":"ok","timestamp":1625212200283,"user_tz":-480,"elapsed":448,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"6fd4d41f-b358-41b0-8451-1a069125b3bc"},"source":["datasets = load_dataset(\"klue\", task)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Reusing dataset klue (/root/.cache/huggingface/datasets/klue/nli/1.0.0/55ff8f92b7a4b9842be6514ce0b4b5295b46d5e493f8bb5760da4be717018f90)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTjvfHK2KDfY","executionInfo":{"status":"ok","timestamp":1625212200284,"user_tz":-480,"elapsed":23,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"b895c563-8c57-40d0-b810-66f6848605a8"},"source":["datasets"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['guid', 'hypothesis', 'label', 'premise', 'source'],\n","        num_rows: 24998\n","    })\n","    validation: Dataset({\n","        features: ['guid', 'hypothesis', 'label', 'premise', 'source'],\n","        num_rows: 3000\n","    })\n","})"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5EcTpMZrKGX7","executionInfo":{"status":"ok","timestamp":1625212200284,"user_tz":-480,"elapsed":15,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"58e867be-f817-4313-b3a4-32625fcf912f"},"source":["datasets[\"train\"][0]"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'guid': 'klue-nli-v1_train_00000',\n"," 'hypothesis': '힛걸 진심 최고로 멋지다.',\n"," 'label': 0,\n"," 'premise': '힛걸 진심 최고다 그 어떤 히어로보다 멋지다',\n"," 'source': 'NSMC'}"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"Pu4y-TVhKLY6"},"source":["## 시각화 함수"]},{"cell_type":"code","metadata":{"id":"yH070sQdKJMK","executionInfo":{"status":"ok","timestamp":1625212200285,"user_tz":-480,"elapsed":13,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["def show_random_elements(dataset, num_examples=10):\n","    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n","\n","    picks = []\n","    \n","    for _ in range(num_examples):\n","        pick = random.randint(0, len(dataset)-1)\n","\n","        # 이미 등록된 예제가 뽑힌 경우, 다시 추출\n","        while pick in picks:\n","            pick = random.randint(0, len(dataset)-1)\n","\n","        picks.append(pick)\n","\n","    # 임의로 추출된 인덱스들로 구성된 데이터 프레임 선언\n","    df = pd.DataFrame(dataset[picks])\n","\n","    for column, typ in dataset.features.items():\n","        # 라벨 클래스를 스트링으로 변환\n","        if isinstance(typ, ClassLabel):\n","            df[column] = df[column].transform(lambda i: typ.names[i])\n","\n","    display(HTML(df.to_html()))"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlLss2JRKPVC"},"source":["앞서 정의한 함수를 활용해 훈련 데이터를 살펴보도록 합시다.\n","\n","이처럼 데이터를 살펴보는 것의 장점으로는 각 라벨에 어떠한 문장들이 해당하는지에 대한 감을 익힐 수 있다는데에 있습니다.\n","\n","KLUE NLI는 entailment, neutral 그리고 contradiction 세 개의 라벨을 지니는 데이터셋임을 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":631},"id":"0GVce5ULKNdM","executionInfo":{"status":"ok","timestamp":1625212200285,"user_tz":-480,"elapsed":11,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"b4734178-f514-41ab-d8e0-7e978bc28c04"},"source":["show_random_elements(datasets[\"train\"])"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>guid</th>\n","      <th>hypothesis</th>\n","      <th>label</th>\n","      <th>premise</th>\n","      <th>source</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>klue-nli-v1_train_07128</td>\n","      <td>러브 라이브는 학교 아이돌에 관한내용이다.</td>\n","      <td>entailment</td>\n","      <td>또한, 러브라이브는 오토노키자카 학원을 구하기 위해 코사카 호노카를 비롯한 총 9명의 뮤즈 부원들이 학교 아이돌을 하는 내용이다.</td>\n","      <td>wikinews</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>klue-nli-v1_train_08462</td>\n","      <td>허쉬의 카카오 농장이 전세계에서 가장 크다.</td>\n","      <td>neutral</td>\n","      <td>미국 최대의 초콜릿 제조업체인 허쉬 역시 코트 디부아르 뿐 아니라 서 아프리카 지역에 몇 개의 카카오 농장을 운영하고 있습니다.</td>\n","      <td>wikinews</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>klue-nli-v1_train_07972</td>\n","      <td>버스가 가장 편리하였습니다.</td>\n","      <td>neutral</td>\n","      <td>메트로, 버스 등 교통이 매우 편리하였습니다.</td>\n","      <td>airbnb</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>klue-nli-v1_train_24858</td>\n","      <td>와인 맛은 별로였습니다.</td>\n","      <td>contradiction</td>\n","      <td>환영하는 의미로 준 와인 맛도 좋았습니다.</td>\n","      <td>airbnb</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>klue-nli-v1_train_00380</td>\n","      <td>2편의 흥행을 재현하려 했으나 1편을 재현한 졸작.</td>\n","      <td>contradiction</td>\n","      <td>1편의 흥행을 재현하려 했으나 2편을 재현한 졸작</td>\n","      <td>NSMC</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>klue-nli-v1_train_10771</td>\n","      <td>센터에 세워지는 건물들은 금속가공 산업의 육성책 중 하나이다.</td>\n","      <td>neutral</td>\n","      <td>센터에는 금속가공 중소기업들이 이용할 수 있는 3개동의 건물과 특수열처리 등 12종의 대형장비가 구축된다.</td>\n","      <td>wikitree</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>klue-nli-v1_train_02807</td>\n","      <td>곤지암 정신병원에는 귀신이 나온다는 괴담이 돌았다.</td>\n","      <td>entailment</td>\n","      <td>귀신이 나온다는 괴담이 돌며 실제 체험을 위해 방문했던 사람들이 실종되었다는 곤지암 정신병원에 남녀 7인으로 이루어진 체험단이 방문한다.</td>\n","      <td>wikipedia</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>klue-nli-v1_train_11476</td>\n","      <td>처음부터 끝까지 지루한 영화였다.</td>\n","      <td>contradiction</td>\n","      <td>스케일부터가 남다름 처음부터 끝까지 지루함이란 찾아볼수없었다</td>\n","      <td>NSMC</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>klue-nli-v1_train_16718</td>\n","      <td>이번 결정에 국방위원회의 명의는 없었다.</td>\n","      <td>contradiction</td>\n","      <td>이번 결정은 조선로동당 중앙위원회를 비롯한 당 중앙군사위원회, 국방위원회, 최고인민회의 상임위원회 명의로 나온 것으로 알려졌다.</td>\n","      <td>wikinews</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>klue-nli-v1_train_08369</td>\n","      <td>문화재위원회 지정 심의 시에는 다양한 분야의 전문가가 모여 검토를 진행한다.</td>\n","      <td>neutral</td>\n","      <td>문화재청은 지정 예고 기간 동안 제출된 의견은 문화재위원회 지정 심의 시 검토할 예정이라고 밝혔다.</td>\n","      <td>wikinews</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"8dRj2qWuKTcS"},"source":["훈련 과정 중 모델의 성능을 파악하기 위한 메트릭을 설정합니다.\n","\n","datasets 라이브러리에는 이미 구현된 메트릭을 사용할 수 있는 load_metric 함수가 있습니다.\n","\n","그 중 GLUE 데이터셋에 이미 다양한 메트릭이 구현되어 있으므로, GLUE 그 중에서도 KLUE NLI와 동일한 accuracy 메트릭을 사용하는 qnli 태스크의 메트릭을 사용합니다."]},{"cell_type":"code","metadata":{"id":"8XiFjDGdKQ8i","executionInfo":{"status":"ok","timestamp":1625212200567,"user_tz":-480,"elapsed":290,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["metric = load_metric(\"glue\", \"qnli\")"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xWj49T0EKYMl"},"source":["accuracy 메트릭이 정상적으로 작동하는지 확인하기 위해, 랜덤한 예측 값과 라벨 값을 생성합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gEGMy-p0KWwm","executionInfo":{"status":"ok","timestamp":1625212200567,"user_tz":-480,"elapsed":5,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"80732831-c06b-4fbc-f438-c7162b03f01a"},"source":["fake_preds = np.random.randint(0, 2, size=(64,))\n","fake_labels = np.random.randint(0, 2, size=(64,))\n","fake_preds, fake_labels"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n","        1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n","        0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1]),\n"," array([1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n","        0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n","        0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1]))"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a97GiZs8KaAT","executionInfo":{"status":"ok","timestamp":1625212200567,"user_tz":-480,"elapsed":4,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"77016251-6269-4d08-c1ef-8086b123ffda"},"source":["\n","metric.compute(predictions=fake_preds, references=fake_labels)"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.46875}"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"a3DN0T5KKcwR"},"source":["## 학습에 활용할 토크나이저를 로드"]},{"cell_type":"code","metadata":{"id":"NI1pgSjaKbgS","executionInfo":{"status":"ok","timestamp":1625212200887,"user_tz":-480,"elapsed":323,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tYjzvDNSKjZv"},"source":["로드된 토크나이저가 두 개 문장을 토큰화하는 방식을 파악하기 위해 두 문장을 입력 값으로 넣어줘보도록 합시다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DZjMwjUmKgMs","executionInfo":{"status":"ok","timestamp":1625212200887,"user_tz":-480,"elapsed":8,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"207dbfab-bcd1-49d5-c2c5-bd01499d13ed"},"source":["tokenizer(\"힛걸 진심 최고로 멋지다.\", \"힛걸 진심 최고다 그 어떤 히어로보다 멋지다\")"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [0, 3, 7254, 3841, 2200, 11980, 2062, 18, 2, 3, 7254, 3841, 2062, 636, 3711, 12717, 2178, 2062, 11980, 2062, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"i_O07-xnKoZy"},"source":["input_ids를 보시면 cls_token에 해당하는 2번 토큰이 가장 좌측에 붙게 되며, sep_token의 3번 토큰이 각각 중간과 가장 우측에 더해진 것을 확인할 수 있습니다.\n","\n","이제 앞서 로드한 데이터셋에서 각 문장에 해당하는 value 를 뽑아주기 위한 key 를 정의합니다.\n","\n","앞서 KLUE NLI 데이터셋의 두 문장은 각각 premise와 hypothesis라는 이름으로 정의된 것을 확인하였으니, 두 문장의 key 는 마찬가지로 각각 premise, hypothesis가 되게 됩니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WQS8HleKld8","executionInfo":{"status":"ok","timestamp":1625212200887,"user_tz":-480,"elapsed":6,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"dff6bb83-b2ae-40c0-ef52-918c4ecf0412"},"source":["sentence1_key, sentence2_key = (\"premise\", \"hypothesis\")\n","print(f\"Sentence 1: {datasets['train'][0][sentence1_key]}\")\n","print(f\"Sentence 2: {datasets['train'][0][sentence2_key]}\")"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Sentence 1: 힛걸 진심 최고다 그 어떤 히어로보다 멋지다\n","Sentence 2: 힛걸 진심 최고로 멋지다.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jXDqiu5tK1Vp"},"source":["이제 key 도 확인이 되었으니, 데이터셋에서 각 예제들을 뽑아와 토큰화 할 수 있는 함수를 아래와 같이 정의해줍니다.\n","\n","해당 함수는 모델을 훈련하기 앞서 데이터셋을 미리 토큰화 시켜놓는 작업을 위한 콜백 함수로 사용되게 됩니다.\n","\n","인자로 넣어주는 truncation는 모델이 입력 받을 수 있는 최대 길이 이상의 토큰 시퀀스가 들어오게 될 경우, 최대 길이 기준으로 시퀀스를 자르라는 의미를 지닙니다.\n","\n","( * return_token_type_ids는 토크나이저가 token_type_ids를 반환하도록 할 것인지를 결정하는 인자입니다. transformers==4.7.0 기준으로 token_type_ids가 기본적으로 반환되므로 token_type_ids 자체를 사용하지 않는 RoBERTa 모델을 활용하기 위해 해당 인자를 False로 설정해주도록 합니다.)"]},{"cell_type":"code","metadata":{"id":"TOWIOfroKyel","executionInfo":{"status":"ok","timestamp":1625212200888,"user_tz":-480,"elapsed":6,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["def preprocess_function(examples):\n","    return tokenizer(\n","        examples[sentence1_key],\n","        examples[sentence2_key],\n","        truncation=True,\n","        return_token_type_ids=False,\n","    )"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mANA0-hkK5Uo"},"source":["앞서 정의한 process_function은 여러 개의 예제 데이터를 받을 수도 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NicnWjlWK3yu","executionInfo":{"status":"ok","timestamp":1625212200888,"user_tz":-480,"elapsed":6,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"dea64bbc-59e1-4929-89ab-5bc277035caf"},"source":["preprocess_function(datasets[\"train\"][:5])"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': [[0, 3, 7254, 3841, 2062, 636, 3711, 12717, 2178, 2062, 11980, 2062, 2, 3, 7254, 3841, 2200, 11980, 2062, 18, 2], [0, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 2, 3911, 2377, 2366, 1525, 2062, 18, 2], [0, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 2, 1282, 2955, 3308, 2052, 3944, 11580, 2359, 2062, 18, 2], [0, 3911, 2377, 2366, 1521, 3061, 4785, 1282, 2955, 3308, 3515, 2170, 22, 2532, 5675, 2, 3911, 2377, 2366, 5105, 2318, 831, 717, 2886, 2069, 575, 555, 2062, 18, 2], [0, 10522, 2548, 2500, 6328, 2170, 6189, 5916, 4015, 2116, 1039, 2219, 3606, 18, 2, 10522, 2548, 2500, 6328, 27135, 5916, 4015, 1642, 2015, 2259, 4258, 2219, 3606, 18, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"deDviyLbMlSG"},"source":["이제 정의된 전처리 함수를 활용해 데이터셋을 미리 토큰화시키는 작업을 수행합니다.\n","\n","datasets 라이브러리를 통해 얻어진 DatasetDict 객체는 map() 함수를 지원하므로, 정의된 전처리 함수를 데이터셋 토큰화를 위한 콜백 함수로 map() 함수 인자로 넘겨주면 됩니다.\n","\n","보다 자세한 내용은 문서를 참조해주시면 됩니다."]},{"cell_type":"code","metadata":{"id":"q4dCpm2GK7nE","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["b87bf07b6292456e9f593ac0b5967f5d","3fbce56a04874cb5a2acf16ebc08aa85","445d32afb0364dc68430410b8b7cf72a","7ef484bdb564483a8e730c9d383f48b3","cdd68eab70a04d44a7b75c07d58decf5","e997953b0dce49bc8152f7e43b91951c","64a56163f70649a28c99aff5c1725fd7","aa41fa287a644dad8dca2d01830fbcc8","ed1c2a0949a44034b55b4cb81083b35b","73983738d4b24af3a8dff7f453fce126","c081f0f3b0324f789e62bde11ec2f008","65a3ee852053471b8e435ed9bd7bf098","0679fe589e9745729937c035ad81021d","630fe4ea9f394f05a2cfabeb89f4e629","2553fbac5c2148d082605f8856662986","8910c4bab8e24d71b175cfcb58c05b21"]},"executionInfo":{"status":"ok","timestamp":1625212225146,"user_tz":-480,"elapsed":2231,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"62b5cf5a-22f7-4739-c8f5-54159453766e"},"source":["encoded_datasets = datasets.map(preprocess_function, batched=True)"],"execution_count":35,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b87bf07b6292456e9f593ac0b5967f5d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed1c2a0949a44034b55b4cb81083b35b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C9CwdBmWMpU6"},"source":["## 학습을 위한 모델을 로드\n","\n","앞서 살펴본 바와 같이 KLUE NLI에는 총 3개의 클래스가 존재하므로, 3개의 클래스를 예측할 수 있는 SequenceClassification 구조로 모델을 로드하도록 합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":171,"referenced_widgets":["3e4a9a45b3a1498281a1b9b3b906dfda","3d667f490d3740b0b75d68f5f4510ea1","1cd7b1879c33475583c762e736a40cfc","d0f4d751fa734090a2cb3d63219cf0dd","286a948ae9e349518928376b2405a9e9","6350a75a3ec846d7a67b663cf8981c9a","546e7d4bead042948c5065ba072b897e","148781bdea454c99806309a20bdebd7e"]},"id":"4MD7YnD4MnxK","executionInfo":{"status":"ok","timestamp":1625212246354,"user_tz":-480,"elapsed":10409,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"e1b40ad6-5cb8-49a9-b949-eeccf9721013"},"source":["num_labels = 3\n","model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"],"execution_count":36,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e4a9a45b3a1498281a1b9b3b906dfda","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=442653775.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Pmbt8LQhMsmU"},"source":["모델을 로드할 때 발생하는 경고 문구는 두 가지 의미를 지닙니다.\n","\n","Masked Language Modeling 을 위해 존재했던 lm_head가 현재는 사용되지 않고 있음을 의미합니다.\n","문장 분류를 위한 classifier 레이어를 백본 모델 뒤에 이어 붙였으나 아직 훈련이 되지 않았으므로, 학습을 수행해야 함을 의미합니다.\n","마지막으로 앞서 정의한 메트릭을 모델 예측 결과에 적용하기 위한 함수를 정의합니다.\n","\n","입력으로 들어오는 eval_pred는 EvalPrediction 객체이며, 모델의 클래스 별 예측 값과 정답 값을 지닙니다.\n","\n","클래스 별 예측 중 가장 높은 라벨을 argmax()를 통해 뽑아낸 후, 정답 라벨과 비교를 하게 됩니다."]},{"cell_type":"code","metadata":{"id":"g_WvInk9Mq82","executionInfo":{"status":"ok","timestamp":1625212248885,"user_tz":-480,"elapsed":248,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    predictions = np.argmax(predictions, axis=1)\n","    return metric.compute(predictions=predictions, references=labels)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjwCdcbkMwCi"},"source":["\n","이제 앞서 정의한 정보들을 바탕으로 transformers에서 제공하는 Trainer 객체를 활용하기 위한 인자 관리 클래스를 초기화합니다.\n","\n","metric_name은 앞서 얻어진 메트릭 함수를 활용했을 때, 아래와 같이 dict 형식으로 결과 값이 반환되는데 여기서 우리가 사용할 key 를 정의해준다고 생각하시면 됩니다.\n","\n",">>> metric.compute(predictions=fake_preds, references=fake_labels)\n","{'accuracy': 0.515625}\n","각 인자에 대한 자세한 설명은 문서에서 참조해주시면 됩니다."]},{"cell_type":"code","metadata":{"id":"fV19XyCWMuDV","executionInfo":{"status":"ok","timestamp":1625212264372,"user_tz":-480,"elapsed":248,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["metric_name = \"accuracy\"\n","\n","args = TrainingArguments(\n","    \"test-nli\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=metric_name,\n",")"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MX1nBmV2Mzfr"},"source":["이제 로드한 모델, 인자 관리 클래스, 데이터셋 등을 Trainer 클래스를 초기화에 넘겨주도록 합니다.\n","\n","(TIP: Q: 이미 encoded_datasets을 만드는 과정에 토큰화가 이루어졌는데 토크나이저를 굳이 넘겨주는 이유가 무엇인가요?,\n","A: 토큰화는 이루어졌지만 학습 과정 시, 데이터를 배치 단위로 넘겨주는 과정에서 배치에 포함된 가장 긴 시퀀스 기준으로 truncation을 수행하고 최대 길이 시퀀스 보다 짧은 시퀀스들은 그 길이만큼 padding을 수행해주기 위함입니다.)"]},{"cell_type":"code","metadata":{"id":"GnLUUTsOMx09","executionInfo":{"status":"ok","timestamp":1625212291090,"user_tz":-480,"elapsed":12150,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=encoded_datasets[\"train\"],\n","    eval_dataset=encoded_datasets[\"validation\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HT_Kzlk1M22D"},"source":["이제 정의된 Trainer 객체를 다음과 같이 훈련시킬 수 있습니다.\n","\n","에폭이 지남에 따라 Loss 는 떨어지고, 앞서 선정한 메트릭인 Accuracy 는 증가하는 것을 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"1XbEHfcKM4Op","executionInfo":{"status":"ok","timestamp":1625214087257,"user_tz":-480,"elapsed":370194,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"009c656c-65d5-4380-a96e-918ae3ae905d"},"source":["trainer.train()"],"execution_count":40,"outputs":[{"output_type":"stream","text":["The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: guid, hypothesis, premise, source.\n","***** Running training *****\n","  Num examples = 24998\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 3910\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3129' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3129/3910 23:33 < 05:53, 2.21 it/s, Epoch 4/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.607200</td>\n","      <td>0.432421</td>\n","      <td>0.839333</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.279100</td>\n","      <td>0.423450</td>\n","      <td>0.857000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.173900</td>\n","      <td>0.464753</td>\n","      <td>0.858000</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","    <div>\n","      \n","      <progress value='66' max='94' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [66/94 00:08 < 00:03, 7.24 it/s]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: guid, hypothesis, premise, source.\n","***** Running Evaluation *****\n","  Num examples = 3000\n","  Batch size = 32\n","Saving model checkpoint to test-nli/checkpoint-782\n","Configuration saved in test-nli/checkpoint-782/config.json\n","Model weights saved in test-nli/checkpoint-782/pytorch_model.bin\n","tokenizer config file saved in test-nli/checkpoint-782/tokenizer_config.json\n","Special tokens file saved in test-nli/checkpoint-782/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: guid, hypothesis, premise, source.\n","***** Running Evaluation *****\n","  Num examples = 3000\n","  Batch size = 32\n","Saving model checkpoint to test-nli/checkpoint-1564\n","Configuration saved in test-nli/checkpoint-1564/config.json\n","Model weights saved in test-nli/checkpoint-1564/pytorch_model.bin\n","tokenizer config file saved in test-nli/checkpoint-1564/tokenizer_config.json\n","Special tokens file saved in test-nli/checkpoint-1564/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: guid, hypothesis, premise, source.\n","***** Running Evaluation *****\n","  Num examples = 3000\n","  Batch size = 32\n","Saving model checkpoint to test-nli/checkpoint-2346\n","Configuration saved in test-nli/checkpoint-2346/config.json\n","Model weights saved in test-nli/checkpoint-2346/pytorch_model.bin\n","tokenizer config file saved in test-nli/checkpoint-2346/tokenizer_config.json\n","Special tokens file saved in test-nli/checkpoint-2346/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: guid, hypothesis, premise, source.\n","***** Running Evaluation *****\n","  Num examples = 3000\n","  Batch size = 32\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='3910' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [3910/3910 29:53, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.607200</td>\n","      <td>0.432421</td>\n","      <td>0.839333</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.279100</td>\n","      <td>0.423450</td>\n","      <td>0.857000</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.173900</td>\n","      <td>0.464753</td>\n","      <td>0.858000</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.097100</td>\n","      <td>0.604402</td>\n","      <td>0.865667</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.070100</td>\n","      <td>0.705257</td>\n","      <td>0.864333</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving model checkpoint to test-nli/checkpoint-3128\n","Configuration saved in test-nli/checkpoint-3128/config.json\n","Model weights saved in test-nli/checkpoint-3128/pytorch_model.bin\n","tokenizer config file saved in test-nli/checkpoint-3128/tokenizer_config.json\n","Special tokens file saved in test-nli/checkpoint-3128/special_tokens_map.json\n","The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: guid, hypothesis, premise, source.\n","***** Running Evaluation *****\n","  Num examples = 3000\n","  Batch size = 32\n","Saving model checkpoint to test-nli/checkpoint-3910\n","Configuration saved in test-nli/checkpoint-3910/config.json\n","Model weights saved in test-nli/checkpoint-3910/pytorch_model.bin\n","tokenizer config file saved in test-nli/checkpoint-3910/tokenizer_config.json\n","Special tokens file saved in test-nli/checkpoint-3910/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from test-nli/checkpoint-3128 (score: 0.8656666666666667).\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=3910, training_loss=0.22737782080764965, metrics={'train_runtime': 1794.0685, 'train_samples_per_second': 69.668, 'train_steps_per_second': 2.179, 'total_flos': 5701283955554040.0, 'train_loss': 0.22737782080764965, 'epoch': 5.0})"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"id":"M-9_-6szM1cl","executionInfo":{"status":"error","timestamp":1625214088885,"user_tz":-480,"elapsed":1628,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}},"outputId":"f5548dc7-f130-4764-ef2a-db383495a5df"},"source":["TrainOutput(global_step=3910, training_loss=0.21999031222994675, metrics={'train_runtime': 1761.9721, 'train_samples_per_second': 70.938, 'train_steps_per_second': 2.219, 'total_flos': 5701283955554040.0, 'train_loss': 0.21999031222994675, 'epoch': 5.0})"],"execution_count":41,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-1c86e3fd1f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTrainOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3910\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.21999031222994675\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train_runtime'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1761.9721\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_samples_per_second'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m70.938\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_steps_per_second'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2.219\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_flos'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5701283955554040.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.21999031222994675\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m5.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'TrainOutput' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"l6fxpWHEM-k5"},"source":["Trainer 는 학습을 마치게 되면, load_best_model_at_end=True 인자에 따라 메트릭 기준 가장 좋은 성능을 보였던 체크포인트를 로드하게 됩니다.\n","\n","본 노트북에서는 마지막 에폭 때 가장 좋은 성능을 얻었기에 evaluate를 수행해도 같은 결과가 나오겠습니다."]},{"cell_type":"code","metadata":{"id":"SvEfRylWM9U7","executionInfo":{"status":"aborted","timestamp":1625214088886,"user_tz":-480,"elapsed":1,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["trainer.evaluate()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ovEry32rNDqx"},"source":["지금까지 transformers를 라이브러리 내 문장 분류 모델을 학습하는 과정을 KLUE NLI 데이터셋을 통해 알아보았습니다.\n","\n","본 노트북을 통해 습득한 지식이 여러분의 업무와 학습에 도움이 되었으면 좋겠습니다.\n","\n","허 훈 (huffonism@gmail.com)\n","APPENDIX: 앞서 학습된 모델을 HuggingFace 모델 허브에 업로드하였으니, 아래 예제와 같이 pipeline 함수를 통해 사용이 가능합니다.\n","\n","먼저 text-classification 태스크로 파이프라인 객체를 초기화합니다.\n","\n","( * return_all_scores는 모델이 입력 문장에 대해 측정한 각 라벨에 대한 확률 값을 모두 보여줄 것인지를 결정하는 인자입니다.)"]},{"cell_type":"code","metadata":{"id":"5i4gMtgzNBXs","executionInfo":{"status":"aborted","timestamp":1625214088886,"user_tz":-480,"elapsed":1,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["from transformers import pipeline\n","\n","classifier = pipeline(\n","    \"text-classification\",\n","    model=\"Huffon/klue-roberta-base-nli\",\n","    return_all_scores=True,\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SFHsBmsyNGya"},"source":["NLI는 두 문장의 페어를 입력 값으로 주어야 하기 때문에 구분자 스페셜 토큰을 두 문장 사이에 넣어주기 위해 토크나이저 객체를 로드합니다.\n","\n","[SEP] 문자열을 하드코딩하여 넣어줄 수도 있겠지만, 스페셜 토큰은 토크나이저 마다 다르게 정의되므로 다른 모델을 활용할 때 보다 코드를 재사용할 수 있도록 토크나이저의 sep_token 프로퍼티에 접근하는 방식으로 코드를 작성합니다."]},{"cell_type":"code","metadata":{"id":"TjF3KCinNFgT","executionInfo":{"status":"aborted","timestamp":1625214088886,"user_tz":-480,"elapsed":1,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["tokenizer = AutoTokenizer.from_pretrained(\"Huffon/klue-roberta-base-nli\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HPolxfGZNInr","executionInfo":{"status":"aborted","timestamp":1625214088887,"user_tz":-480,"elapsed":2,"user":{"displayName":"Gnh Prk","photoUrl":"","userId":"12739054429736079584"}}},"source":["tokenizer.sep_token"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lH0xHZBpNPJz"},"source":["sep_token으로 두 문장을 이어 하나의 입력 값으로 파이프라인에 넘겨줍니다.\n","\n","입력된 문장에 대해 모델이 각 라벨에 대해 어떤 확률을 가지고 예측했는지를 확인할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"obFQZXfbNM1Q"},"source":["classifier(f\"흡연하려면 발코니 있는 방을 선택하면 됩니다. {tokenizer.sep_token} 흡연자분들은 발코니가 있는 방이면 발코니에서 흡연이 가능합니다.\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vELrPj3cNThg"},"source":["classifier(f\"호스트분은 영어밖에 못하십니다. {tokenizer.sep_token} 호스트분도 엄청 친절하시고 영어도 잘하십니다.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1wk33TCGNcPG"},"source":["검증 데이터에 존재하는 임의의 문장 페어를 입력해보니, 우리가 원하던 결과를 얻을 수 있었습니다.\n","\n","(cf. NLI 데이터에 대해 학습된 모델을 활용해 Zero-shot Classification을 수행하는 예제가 궁금하신 분들은 해당 노트북을 참조해주세요.)"]},{"cell_type":"code","metadata":{"id":"RZDu3ZmCNY1a"},"source":[""],"execution_count":null,"outputs":[]}]}